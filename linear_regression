import numpy as np

def gradient_descent(x, y, coefs, iterations = 10**5, tol = 1e-6, alpha = 1e-2):
        m = x.shape[0]
        n_iters = 0
        converge = False

        for i in range(iterations):
            coef_init = np.copy(coefs)
            n_iters += 1
            error_start = np.sum(x*coefs, axis = 1) - y.reshape(1,m)
            error_start *= error_start
            error_start = np.sum(error_start) / m
            counter = 0
            for i, c in enumerate(coefs):

                coefs[i] = coefs[i] - \
                    alpha*(1/m)*np.dot(x[:, counter].reshape(1,m), (np.sum(x*coefs, axis = 1) - y.reshape(1,m)).reshape(m,1))[0][0]

                counter += 1

            error_end = np.sum(x*coefs, axis = 1) - y.reshape(1,m)
            error_end *= error_end
            error_end = np.sum(error_end) / m


            if abs((error_start - error_end) / error_start) < tol or error_start < error_end:
                print('Finished AND converged with RMSE' , error_start)
                converge = True
                break

        print('Number of iterations: ', n_iters)
        if converge:
            return coefs
        else:
            print('Finished NOT converged with RMSE' , error_end)
            return coef_init
        

class LinReg():
    def __init__(self, fit_intercept=True, iterations=1):
        self.iterations = iterations
        self.fit_intercept = fit_intercept
        
    
    
    def fit(self, x, y):
        fit_intercept = self.fit_intercept
        x = np.array(x)
        y = np.array(y).reshape(len(y), 1)

        if len(x.shape) == 1:
            x = x.reshape(1, len(x))


        if fit_intercept:
            intercept = np.ones(len(x)).reshape(x.shape[0])
            x = np.column_stack((intercept, x) )
        self.coef = gradient_descent(x, y, np.ones(x.shape[1]), iterations = self.iterations)
        return self
